{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write your name here\n",
    "### This Lab is open from 10/25 at 6 am to 10/25 at 3:30 pm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set called Highway1 (used by  by Carl Hoffstedt in his paper: https://rdrr.io/rforge/alr4/man/Highway1.html) relate the automobile accident rate, in accidents per million vehicle miles to several potential terms. The data include 39 sections of large Highways in the state of Minnesota in 1973. The goal of this analysis is to see how the rate variable are affetcted by some of the variables that are highly correlated with the rate and finding out which ones affect the rate variable the most."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data frame contains the following columns:\n",
    "\n",
    "adt - average daily traffic count in thousands\n",
    "\n",
    "trks - truck volume as a percent of the total volume\n",
    "\n",
    "lane - total number of lanes of traffic\n",
    "\n",
    "acpt - number of access points per mile\n",
    "\n",
    "sigs - number of signalized interchanges per mile\n",
    "\n",
    "itg - number of freeway-type interchanges per mile\n",
    "\n",
    "slim - speed limit in 1973\n",
    "\n",
    "len - length of the Highway segment in miles\n",
    "\n",
    "lwid - lane width, in feet\n",
    "\n",
    "shld - width in feet of outer shoulder on the roadway\n",
    "\n",
    "htype - An indicator of the type of roadway or the source of funding for the road; \"mc\" for major collector, \"fai\" for Federal interstate highways, \"pa\" for principal arterial highway, and \"ma\" for major arterial highways\n",
    "\n",
    "rate - 1973 accident rate per million vehicle miles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Please note that we are using a tiny data set with 39 rows and 11 columns in this lab. So, when we model and fit data, the accuracy is not that good and predictions do not look good as well. We are just learning to use these different models, so it is okay for now. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Each problem is worth 10 points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1\n",
    "This data came from R package which uses index starting at 1 unlike in python where indices  start at 0. When  you upload highway1 data to jupyter notebook, you will see an unnecessory column that says column 0. Also remove the column indicating hiway types as it is a string.\n",
    "Train a linear model with rate as a dependent variable, and 10 numerical columns as dependent variables. Make sure to add a constant in the data so that you also get an intercept in the output. Look at the summary of the model, report the $R^2$ value, find out two variables that have p-values of more than 90% and remove them from the data. Name this new data set that has 8 important independent variables and  rate as a dependent variable as newdata.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rate</th>\n",
       "      <th>len</th>\n",
       "      <th>ADT</th>\n",
       "      <th>trks</th>\n",
       "      <th>sigs1</th>\n",
       "      <th>slim</th>\n",
       "      <th>shld</th>\n",
       "      <th>lane</th>\n",
       "      <th>acpt</th>\n",
       "      <th>itg</th>\n",
       "      <th>lwid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.58</td>\n",
       "      <td>4.99</td>\n",
       "      <td>69</td>\n",
       "      <td>8</td>\n",
       "      <td>0.200401</td>\n",
       "      <td>55</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.20</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.86</td>\n",
       "      <td>16.11</td>\n",
       "      <td>73</td>\n",
       "      <td>8</td>\n",
       "      <td>0.062073</td>\n",
       "      <td>60</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.43</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.02</td>\n",
       "      <td>9.75</td>\n",
       "      <td>49</td>\n",
       "      <td>10</td>\n",
       "      <td>0.102564</td>\n",
       "      <td>60</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.54</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.29</td>\n",
       "      <td>10.65</td>\n",
       "      <td>61</td>\n",
       "      <td>13</td>\n",
       "      <td>0.093897</td>\n",
       "      <td>65</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0.94</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.61</td>\n",
       "      <td>20.01</td>\n",
       "      <td>28</td>\n",
       "      <td>12</td>\n",
       "      <td>0.049975</td>\n",
       "      <td>70</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.65</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rate    len  ADT  trks     sigs1  slim  shld  lane  acpt   itg  lwid\n",
       "0  4.58   4.99   69     8  0.200401    55    10     8   4.6  1.20    12\n",
       "1  2.86  16.11   73     8  0.062073    60    10     4   4.4  1.43    12\n",
       "2  3.02   9.75   49    10  0.102564    60    10     4   4.7  1.54    12\n",
       "3  2.29  10.65   61    13  0.093897    65    10     6   3.8  0.94    12\n",
       "4  1.61  20.01   28    12  0.049975    70    10     4   2.2  0.65    12"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('highway1.csv')\n",
    "df = df.drop('Unnamed: 0', axis = 1)\n",
    "df = df.drop('hwy', axis = 1)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>rate</td>       <th>  R-squared:         </th> <td>   0.743</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.651</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   8.080</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 25 Oct 2019</td> <th>  Prob (F-statistic):</th> <td>5.72e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:56:01</td>     <th>  Log-Likelihood:    </th> <td> -55.125</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    39</td>      <th>  AIC:               </th> <td>   132.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    28</td>      <th>  BIC:               </th> <td>   150.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    10</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   12.8175</td> <td>    5.969</td> <td>    2.147</td> <td> 0.041</td> <td>    0.591</td> <td>   25.044</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>len</th>   <td>   -0.0607</td> <td>    0.033</td> <td>   -1.842</td> <td> 0.076</td> <td>   -0.128</td> <td>    0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ADT</th>   <td>    0.0037</td> <td>    0.032</td> <td>    0.114</td> <td> 0.910</td> <td>   -0.062</td> <td>    0.069</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>trks</th>  <td>   -0.1148</td> <td>    0.103</td> <td>   -1.119</td> <td> 0.272</td> <td>   -0.325</td> <td>    0.095</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sigs1</th> <td>    0.4053</td> <td>    0.404</td> <td>    1.002</td> <td> 0.325</td> <td>   -0.423</td> <td>    1.233</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>slim</th>  <td>   -0.0593</td> <td>    0.063</td> <td>   -0.947</td> <td> 0.352</td> <td>   -0.188</td> <td>    0.069</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>shld</th>  <td>   -0.0908</td> <td>    0.108</td> <td>   -0.844</td> <td> 0.406</td> <td>   -0.311</td> <td>    0.130</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lane</th>  <td>    0.0197</td> <td>    0.274</td> <td>    0.072</td> <td> 0.943</td> <td>   -0.542</td> <td>    0.582</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>acpt</th>  <td>    0.0885</td> <td>    0.031</td> <td>    2.858</td> <td> 0.008</td> <td>    0.025</td> <td>    0.152</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>itg</th>   <td>    0.2059</td> <td>    1.135</td> <td>    0.181</td> <td> 0.857</td> <td>   -2.119</td> <td>    2.531</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lwid</th>  <td>   -0.3867</td> <td>    0.475</td> <td>   -0.815</td> <td> 0.422</td> <td>   -1.359</td> <td>    0.585</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.400</td> <th>  Durbin-Watson:     </th> <td>   2.537</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.819</td> <th>  Jarque-Bera (JB):  </th> <td>   0.239</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.187</td> <th>  Prob(JB):          </th> <td>   0.887</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.913</td> <th>  Cond. No.          </th> <td>2.03e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 2.03e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                   rate   R-squared:                       0.743\n",
       "Model:                            OLS   Adj. R-squared:                  0.651\n",
       "Method:                 Least Squares   F-statistic:                     8.080\n",
       "Date:                Fri, 25 Oct 2019   Prob (F-statistic):           5.72e-06\n",
       "Time:                        14:56:01   Log-Likelihood:                -55.125\n",
       "No. Observations:                  39   AIC:                             132.2\n",
       "Df Residuals:                      28   BIC:                             150.5\n",
       "Df Model:                          10                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         12.8175      5.969      2.147      0.041       0.591      25.044\n",
       "len           -0.0607      0.033     -1.842      0.076      -0.128       0.007\n",
       "ADT            0.0037      0.032      0.114      0.910      -0.062       0.069\n",
       "trks          -0.1148      0.103     -1.119      0.272      -0.325       0.095\n",
       "sigs1          0.4053      0.404      1.002      0.325      -0.423       1.233\n",
       "slim          -0.0593      0.063     -0.947      0.352      -0.188       0.069\n",
       "shld          -0.0908      0.108     -0.844      0.406      -0.311       0.130\n",
       "lane           0.0197      0.274      0.072      0.943      -0.542       0.582\n",
       "acpt           0.0885      0.031      2.858      0.008       0.025       0.152\n",
       "itg            0.2059      1.135      0.181      0.857      -2.119       2.531\n",
       "lwid          -0.3867      0.475     -0.815      0.422      -1.359       0.585\n",
       "==============================================================================\n",
       "Omnibus:                        0.400   Durbin-Watson:                   2.537\n",
       "Prob(Omnibus):                  0.819   Jarque-Bera (JB):                0.239\n",
       "Skew:                           0.187   Prob(JB):                        0.887\n",
       "Kurtosis:                       2.913   Cond. No.                     2.03e+03\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 2.03e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "y = df[[\"len\", \"ADT\", \"trks\", \"sigs1\", \"slim\", \"shld\", \"lane\", \"acpt\", \"itg\", \"lwid\"]]\n",
    "x = df[\"rate\"]\n",
    "y = sm.add_constant(y)\n",
    "model = sm.OLS(x, y).fit()\n",
    "predictions = model.predict(y)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R squared value is 0.743"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rate</th>\n",
       "      <th>len</th>\n",
       "      <th>trks</th>\n",
       "      <th>sigs1</th>\n",
       "      <th>slim</th>\n",
       "      <th>shld</th>\n",
       "      <th>acpt</th>\n",
       "      <th>itg</th>\n",
       "      <th>lwid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.58</td>\n",
       "      <td>4.99</td>\n",
       "      <td>8</td>\n",
       "      <td>0.200401</td>\n",
       "      <td>55</td>\n",
       "      <td>10</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.20</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.86</td>\n",
       "      <td>16.11</td>\n",
       "      <td>8</td>\n",
       "      <td>0.062073</td>\n",
       "      <td>60</td>\n",
       "      <td>10</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.43</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.02</td>\n",
       "      <td>9.75</td>\n",
       "      <td>10</td>\n",
       "      <td>0.102564</td>\n",
       "      <td>60</td>\n",
       "      <td>10</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.54</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.29</td>\n",
       "      <td>10.65</td>\n",
       "      <td>13</td>\n",
       "      <td>0.093897</td>\n",
       "      <td>65</td>\n",
       "      <td>10</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0.94</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.61</td>\n",
       "      <td>20.01</td>\n",
       "      <td>12</td>\n",
       "      <td>0.049975</td>\n",
       "      <td>70</td>\n",
       "      <td>10</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.65</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rate    len  trks     sigs1  slim  shld  acpt   itg  lwid\n",
       "0  4.58   4.99     8  0.200401    55    10   4.6  1.20    12\n",
       "1  2.86  16.11     8  0.062073    60    10   4.4  1.43    12\n",
       "2  3.02   9.75    10  0.102564    60    10   4.7  1.54    12\n",
       "3  2.29  10.65    13  0.093897    65    10   3.8  0.94    12\n",
       "4  1.61  20.01    12  0.049975    70    10   2.2  0.65    12"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(\"ADT\", axis = 1)\n",
    "df = df.drop(\"lane\", axis = 1)\n",
    "newdata = df\n",
    "newdata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2\n",
    "In this problem we will just pick the variable named 'sigs1' and the 'rate' variable from newdata. We will use test/train validation method to see how our model does. Denote sigs1 column by x and rate column by y. Split the data x and y with a 80, 20 rule to x_train, x_test, y_train and y_test. This means that you are dividing x data to two data sets of x_train and x_test with 80% and 20 % of the data randomly and the same for y. Report the shapes of these 4 data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31,) (31,)\n",
      "(8,) (8,)\n"
     ]
    }
   ],
   "source": [
    "# Python has a package called sklearn that has this split function inside it.\n",
    "# Please import the following package that wil help us splitting the data.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x = df['sigs1']\n",
    "y = df['rate']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "print (X_train.shape, y_train.shape)\n",
    "print (X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read more about train and test splitting here.\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3\n",
    "Now train a linear regression model using x_train and y_train. Do not forget to add a constant to the x_train data. Report your $R^2$ and and coefficients. Now make a prediction of y values using the data set x_test. Make sure to add constant to this x_test data before making predictions. Name this predictions as y_pred. You just need to use the predict function with your model explained here \n",
    "https://www.statsmodels.org/dev/examples/notebooks/generated/predict.html\n",
    "Now display y_pred and y_test side by side to see how the predictions match up. Finally find the $R^2$ for the test data. Formula for the test set $R^2$ is goven below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (1,8) and (2,) not aligned: 8 (dim 1) != 2 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-e072066dd539>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_constant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOLS\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, exog, transform, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1036\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1037\u001b[0m         predict_results = self.model.predict(self.params, exog, *args,\n\u001b[1;32m-> 1038\u001b[1;33m                                              **kwargs)\n\u001b[0m\u001b[0;32m   1039\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1040\u001b[0m         if exog_index is not None and not hasattr(predict_results,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\statsmodels\\regression\\linear_model.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, params, exog)\u001b[0m\n\u001b[0;32m    362\u001b[0m             \u001b[0mexog\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexog\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 364\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    365\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    366\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_distribution\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdist_class\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (1,8) and (2,) not aligned: 8 (dim 1) != 2 (dim 0)"
     ]
    }
   ],
   "source": [
    "y = y_train\n",
    "x = X_train\n",
    "x = sm.add_constant(x)\n",
    "model = sm.OLS(y, x).fit()\n",
    "y_pred = model.predict(X_test)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y_true and y_pred have different number of output (1!=2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-65-7fcfd38683ff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mr2_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\regression.py\u001b[0m in \u001b[0;36mr2_score\u001b[1;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[0;32m    536\u001b[0m     \"\"\"\n\u001b[0;32m    537\u001b[0m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[1;32m--> 538\u001b[1;33m         y_true, y_pred, multioutput)\n\u001b[0m\u001b[0;32m    539\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput)\u001b[0m\n\u001b[0;32m     87\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m         raise ValueError(\"y_true and y_pred have different number of output \"\n\u001b[1;32m---> 89\u001b[1;33m                          \"({0}!={1})\".format(y_true.shape[1], y_pred.shape[1]))\n\u001b[0m\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[0mn_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: y_true and y_pred have different number of output (1!=2)"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 4\n",
    "Repeat probem 3 without adding the constant this time. This just means that your model is simply $y \\approx bx$ instead of $y \\approx a+bx$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 5\n",
    "In problem 1, you created a data set with only important columns. Use this data set to fit a multivariable regression model by splitting data to training and testing with 80, 20 rule. Report your training set $R^2$, coefficients and  predicted values and test set $R^2$."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
