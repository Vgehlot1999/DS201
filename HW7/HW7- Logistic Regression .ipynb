{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write your name here\n",
    "### This HW is due on  11/3 at 11:59 pm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset is about participants who completed the personal information form and a divorce predictors scale.\n",
    "The data is a modified version of the publicly available at https://archive.ics.uci.edu/ml/datasets/Divorce+Predictors+data+set (by injecting noise so you will not replicate the results on uci web- site). There are 170 participants and 54 attributes (or predictor variables) that are all real-valued. The dataset is named as divorce.csv. The last column of the CSV file is labeled y (1 means “divorce”, 0 means “no divorce”). Each column is for one feature (predictor variable), and each row is a sample (participant). A detailed explanation for each feature (predictor variable) can be found at the website link above. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using sklearn very often from now on. Please read all about it here https://scikit-learn.org/stable/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1\n",
    "Please load the divorce data that is in csv form. Make sure to add Header = None when uploading it. Separate the last column as y and all other columns as x. Use all the data x and y to trian a logistic regression model using LogisticRegression function from sklearn library here\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "Once you fit the model, make predictions on the whole data set x, report the accuracy score and the confusion matrix (Will discuss these details in lecutre on Wednesday). ( 20 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.560903</td>\n",
       "      <td>3.681587</td>\n",
       "      <td>3.450467</td>\n",
       "      <td>3.211998</td>\n",
       "      <td>-1.203045</td>\n",
       "      <td>0.597706</td>\n",
       "      <td>-0.970093</td>\n",
       "      <td>-0.750970</td>\n",
       "      <td>-0.511495</td>\n",
       "      <td>-0.133660</td>\n",
       "      <td>...</td>\n",
       "      <td>2.077401</td>\n",
       "      <td>1.184182</td>\n",
       "      <td>3.955069</td>\n",
       "      <td>2.608046</td>\n",
       "      <td>2.303629</td>\n",
       "      <td>1.721660</td>\n",
       "      <td>3.275018</td>\n",
       "      <td>1.761019</td>\n",
       "      <td>1.215237</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.153272</td>\n",
       "      <td>5.173858</td>\n",
       "      <td>4.100690</td>\n",
       "      <td>2.580173</td>\n",
       "      <td>3.305788</td>\n",
       "      <td>-1.505512</td>\n",
       "      <td>-0.029398</td>\n",
       "      <td>5.702657</td>\n",
       "      <td>2.230281</td>\n",
       "      <td>4.975496</td>\n",
       "      <td>...</td>\n",
       "      <td>3.467076</td>\n",
       "      <td>2.451984</td>\n",
       "      <td>3.504294</td>\n",
       "      <td>5.324240</td>\n",
       "      <td>4.480607</td>\n",
       "      <td>5.375248</td>\n",
       "      <td>2.270379</td>\n",
       "      <td>2.167944</td>\n",
       "      <td>2.191214</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.226241</td>\n",
       "      <td>1.575322</td>\n",
       "      <td>2.389117</td>\n",
       "      <td>2.725405</td>\n",
       "      <td>-0.304562</td>\n",
       "      <td>2.832803</td>\n",
       "      <td>1.787779</td>\n",
       "      <td>0.565755</td>\n",
       "      <td>1.328212</td>\n",
       "      <td>2.335353</td>\n",
       "      <td>...</td>\n",
       "      <td>1.200917</td>\n",
       "      <td>1.241794</td>\n",
       "      <td>2.207492</td>\n",
       "      <td>1.228034</td>\n",
       "      <td>0.870052</td>\n",
       "      <td>1.685040</td>\n",
       "      <td>2.341985</td>\n",
       "      <td>-0.444320</td>\n",
       "      <td>2.527452</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.553458</td>\n",
       "      <td>2.859042</td>\n",
       "      <td>2.928414</td>\n",
       "      <td>1.833241</td>\n",
       "      <td>1.271119</td>\n",
       "      <td>4.165213</td>\n",
       "      <td>2.078597</td>\n",
       "      <td>4.506175</td>\n",
       "      <td>2.521628</td>\n",
       "      <td>2.747315</td>\n",
       "      <td>...</td>\n",
       "      <td>3.196291</td>\n",
       "      <td>2.204824</td>\n",
       "      <td>3.664982</td>\n",
       "      <td>3.689508</td>\n",
       "      <td>2.577677</td>\n",
       "      <td>3.171884</td>\n",
       "      <td>2.164660</td>\n",
       "      <td>1.813024</td>\n",
       "      <td>1.376033</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.506547</td>\n",
       "      <td>1.419223</td>\n",
       "      <td>1.716153</td>\n",
       "      <td>1.319274</td>\n",
       "      <td>2.853840</td>\n",
       "      <td>0.047412</td>\n",
       "      <td>-0.016515</td>\n",
       "      <td>0.620795</td>\n",
       "      <td>1.202992</td>\n",
       "      <td>0.078347</td>\n",
       "      <td>...</td>\n",
       "      <td>1.806657</td>\n",
       "      <td>2.085539</td>\n",
       "      <td>2.012551</td>\n",
       "      <td>1.899477</td>\n",
       "      <td>1.510134</td>\n",
       "      <td>1.373350</td>\n",
       "      <td>2.551119</td>\n",
       "      <td>0.846321</td>\n",
       "      <td>-0.066858</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  1.560903  3.681587  3.450467  3.211998 -1.203045  0.597706 -0.970093   \n",
       "1  4.153272  5.173858  4.100690  2.580173  3.305788 -1.505512 -0.029398   \n",
       "2  2.226241  1.575322  2.389117  2.725405 -0.304562  2.832803  1.787779   \n",
       "3  3.553458  2.859042  2.928414  1.833241  1.271119  4.165213  2.078597   \n",
       "4  0.506547  1.419223  1.716153  1.319274  2.853840  0.047412 -0.016515   \n",
       "\n",
       "         7         8         9   ...        45        46        47        48  \\\n",
       "0 -0.750970 -0.511495 -0.133660  ...  2.077401  1.184182  3.955069  2.608046   \n",
       "1  5.702657  2.230281  4.975496  ...  3.467076  2.451984  3.504294  5.324240   \n",
       "2  0.565755  1.328212  2.335353  ...  1.200917  1.241794  2.207492  1.228034   \n",
       "3  4.506175  2.521628  2.747315  ...  3.196291  2.204824  3.664982  3.689508   \n",
       "4  0.620795  1.202992  0.078347  ...  1.806657  2.085539  2.012551  1.899477   \n",
       "\n",
       "         49        50        51        52        53   54  \n",
       "0  2.303629  1.721660  3.275018  1.761019  1.215237  1.0  \n",
       "1  4.480607  5.375248  2.270379  2.167944  2.191214  1.0  \n",
       "2  0.870052  1.685040  2.341985 -0.444320  2.527452  1.0  \n",
       "3  2.577677  3.171884  2.164660  1.813024  1.376033  1.0  \n",
       "4  1.510134  1.373350  2.551119  0.846321 -0.066858  1.0  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import numpy.matlib\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn import preprocessing\n",
    "import seaborn as sns\n",
    "import scipy.stats as st\n",
    "import matplotlib.colors as colors\n",
    "df = pd.read_csv('divorce.csv', header = None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.560903</td>\n",
       "      <td>3.681587</td>\n",
       "      <td>3.450467</td>\n",
       "      <td>3.211998</td>\n",
       "      <td>-1.203045</td>\n",
       "      <td>0.597706</td>\n",
       "      <td>-0.970093</td>\n",
       "      <td>-0.750970</td>\n",
       "      <td>-0.511495</td>\n",
       "      <td>-0.133660</td>\n",
       "      <td>...</td>\n",
       "      <td>3.357714</td>\n",
       "      <td>2.077401</td>\n",
       "      <td>1.184182</td>\n",
       "      <td>3.955069</td>\n",
       "      <td>2.608046</td>\n",
       "      <td>2.303629</td>\n",
       "      <td>1.721660</td>\n",
       "      <td>3.275018</td>\n",
       "      <td>1.761019</td>\n",
       "      <td>1.215237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.153272</td>\n",
       "      <td>5.173858</td>\n",
       "      <td>4.100690</td>\n",
       "      <td>2.580173</td>\n",
       "      <td>3.305788</td>\n",
       "      <td>-1.505512</td>\n",
       "      <td>-0.029398</td>\n",
       "      <td>5.702657</td>\n",
       "      <td>2.230281</td>\n",
       "      <td>4.975496</td>\n",
       "      <td>...</td>\n",
       "      <td>3.840590</td>\n",
       "      <td>3.467076</td>\n",
       "      <td>2.451984</td>\n",
       "      <td>3.504294</td>\n",
       "      <td>5.324240</td>\n",
       "      <td>4.480607</td>\n",
       "      <td>5.375248</td>\n",
       "      <td>2.270379</td>\n",
       "      <td>2.167944</td>\n",
       "      <td>2.191214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.226241</td>\n",
       "      <td>1.575322</td>\n",
       "      <td>2.389117</td>\n",
       "      <td>2.725405</td>\n",
       "      <td>-0.304562</td>\n",
       "      <td>2.832803</td>\n",
       "      <td>1.787779</td>\n",
       "      <td>0.565755</td>\n",
       "      <td>1.328212</td>\n",
       "      <td>2.335353</td>\n",
       "      <td>...</td>\n",
       "      <td>2.941032</td>\n",
       "      <td>1.200917</td>\n",
       "      <td>1.241794</td>\n",
       "      <td>2.207492</td>\n",
       "      <td>1.228034</td>\n",
       "      <td>0.870052</td>\n",
       "      <td>1.685040</td>\n",
       "      <td>2.341985</td>\n",
       "      <td>-0.444320</td>\n",
       "      <td>2.527452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.553458</td>\n",
       "      <td>2.859042</td>\n",
       "      <td>2.928414</td>\n",
       "      <td>1.833241</td>\n",
       "      <td>1.271119</td>\n",
       "      <td>4.165213</td>\n",
       "      <td>2.078597</td>\n",
       "      <td>4.506175</td>\n",
       "      <td>2.521628</td>\n",
       "      <td>2.747315</td>\n",
       "      <td>...</td>\n",
       "      <td>2.594346</td>\n",
       "      <td>3.196291</td>\n",
       "      <td>2.204824</td>\n",
       "      <td>3.664982</td>\n",
       "      <td>3.689508</td>\n",
       "      <td>2.577677</td>\n",
       "      <td>3.171884</td>\n",
       "      <td>2.164660</td>\n",
       "      <td>1.813024</td>\n",
       "      <td>1.376033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.506547</td>\n",
       "      <td>1.419223</td>\n",
       "      <td>1.716153</td>\n",
       "      <td>1.319274</td>\n",
       "      <td>2.853840</td>\n",
       "      <td>0.047412</td>\n",
       "      <td>-0.016515</td>\n",
       "      <td>0.620795</td>\n",
       "      <td>1.202992</td>\n",
       "      <td>0.078347</td>\n",
       "      <td>...</td>\n",
       "      <td>1.889684</td>\n",
       "      <td>1.806657</td>\n",
       "      <td>2.085539</td>\n",
       "      <td>2.012551</td>\n",
       "      <td>1.899477</td>\n",
       "      <td>1.510134</td>\n",
       "      <td>1.373350</td>\n",
       "      <td>2.551119</td>\n",
       "      <td>0.846321</td>\n",
       "      <td>-0.066858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  1.560903  3.681587  3.450467  3.211998 -1.203045  0.597706 -0.970093   \n",
       "1  4.153272  5.173858  4.100690  2.580173  3.305788 -1.505512 -0.029398   \n",
       "2  2.226241  1.575322  2.389117  2.725405 -0.304562  2.832803  1.787779   \n",
       "3  3.553458  2.859042  2.928414  1.833241  1.271119  4.165213  2.078597   \n",
       "4  0.506547  1.419223  1.716153  1.319274  2.853840  0.047412 -0.016515   \n",
       "\n",
       "         7         8         9   ...        44        45        46        47  \\\n",
       "0 -0.750970 -0.511495 -0.133660  ...  3.357714  2.077401  1.184182  3.955069   \n",
       "1  5.702657  2.230281  4.975496  ...  3.840590  3.467076  2.451984  3.504294   \n",
       "2  0.565755  1.328212  2.335353  ...  2.941032  1.200917  1.241794  2.207492   \n",
       "3  4.506175  2.521628  2.747315  ...  2.594346  3.196291  2.204824  3.664982   \n",
       "4  0.620795  1.202992  0.078347  ...  1.889684  1.806657  2.085539  2.012551   \n",
       "\n",
       "         48        49        50        51        52        53  \n",
       "0  2.608046  2.303629  1.721660  3.275018  1.761019  1.215237  \n",
       "1  5.324240  4.480607  5.375248  2.270379  2.167944  2.191214  \n",
       "2  1.228034  0.870052  1.685040  2.341985 -0.444320  2.527452  \n",
       "3  3.689508  2.577677  3.171884  2.164660  1.813024  1.376033  \n",
       "4  1.899477  1.510134  1.373350  2.551119  0.846321 -0.066858  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df[54]\n",
    "x = df[df.columns[0:54]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "lrmodel = LogisticRegression(solver='lbfgs')\n",
    "lrmodel.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "[[86  0]\n",
      " [ 0 84]]\n"
     ]
    }
   ],
   "source": [
    "ypredlr = lrmodel.predict(x)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y, ypredlr))\n",
    "print(confusion_matrix(y, ypredlr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2\n",
    "Now repeat problem 1 by splitting the data by 80, 20 rule. Please report your accuracy rate and confusion matrix for both the test and the train set. (20 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrmodel = LogisticRegression(solver='lbfgs')\n",
    "lrmodel.fit(x_train, y_train)\n",
    "\n",
    "test_ypredIr = lrmodel.predict(x_test)\n",
    "train_predIr = lrmodel.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy test: 0.9411764705882353\n",
      "[[11  0]\n",
      " [ 2 21]]\n",
      "\n",
      "\n",
      "Accuracy train: 1.0\n",
      "[[75  0]\n",
      " [ 0 61]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy test:\",metrics.accuracy_score(y_test, test_ypredIr))\n",
    "print(confusion_matrix(y_test, test_ypredIr))\n",
    "print(\"\\n\")\n",
    "print(\"Accuracy train:\",metrics.accuracy_score(y_train, train_predIr))\n",
    "print(confusion_matrix(y_train, train_predIr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3\n",
    "Out of 54 features, choose only 40 that are most improtant. Retrain the logistic model by splitting it to 70, 30. You decide how you want to pick 40 important features. Looking at statmodels summary is one way. Sklearn has a feature slection function too, check it out. https://scikit-learn.org/stable/modules/feature_selection.html. Report the accuracy and the confusion matrix. (20 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy test: 0.9803921568627451\n",
      "[[19  0]\n",
      " [ 1 31]]\n",
      "\n",
      "\n",
      "Accuracy train: 1.0\n",
      "[[67  0]\n",
      " [ 0 52]]\n"
     ]
    }
   ],
   "source": [
    "y1 = y\n",
    "x1 = df[df.columns[0:40]]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x1, y1, test_size=0.3)\n",
    "\n",
    "lrmodel = LogisticRegression(solver='lbfgs')\n",
    "lrmodel.fit(x_train, y_train)\n",
    "\n",
    "test_ypredIr = lrmodel.predict(x_test)\n",
    "train_predIr = lrmodel.predict(x_train)\n",
    "\n",
    "print(\"Accuracy test:\",metrics.accuracy_score(y_test, test_ypredIr))\n",
    "print(confusion_matrix(y_test, test_ypredIr))\n",
    "print(\"\\n\")\n",
    "print(\"Accuracy train:\",metrics.accuracy_score(y_train, train_predIr))\n",
    "print(confusion_matrix(y_train, train_predIr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4\n",
    "In this problem, pick only the first two features and retrain the logistic regression model. Write out the accuracy and confusion matrix. (20 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy test: 0.9019607843137255\n",
      "[[24  4]\n",
      " [ 1 22]]\n",
      "\n",
      "\n",
      "Accuracy train: 0.8991596638655462\n",
      "[[51  7]\n",
      " [ 5 56]]\n"
     ]
    }
   ],
   "source": [
    "y2 = y\n",
    "x2 = df[df.columns[0:1]]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x2, y2, test_size=0.3)\n",
    "\n",
    "lrmodel = LogisticRegression(solver='lbfgs')\n",
    "lrmodel.fit(x_train, y_train)\n",
    "\n",
    "test_ypredIr = lrmodel.predict(x_test)\n",
    "train_predIr = lrmodel.predict(x_train)\n",
    "\n",
    "print(\"Accuracy test:\",metrics.accuracy_score(y_test, test_ypredIr))\n",
    "print(confusion_matrix(y_test, test_ypredIr))\n",
    "print(\"\\n\")\n",
    "print(\"Accuracy train:\",metrics.accuracy_score(y_train, train_predIr))\n",
    "print(confusion_matrix(y_train, train_predIr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 5\n",
    "Make a plot of decision boundary given by your model in problem 4. You will have two plots. One plot is with the  training data and the decision boundary and the other one is with the testing data and the decision boundary. Label x axis as Featur 0  and y-axis as Feature 1. In the plot, points from test data will be classified with different colors and are separated by the decision boundary line.\n",
    "(20 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-106-43d999960d81>, line 26)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-106-43d999960d81>\"\u001b[1;36m, line \u001b[1;32m26\u001b[0m\n\u001b[1;33m    Z = lrmodel.predict(np.c_[xx.ravel(), yy.ravel()])\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "x1train, x1test, y1train, y1test = train_test_split(x2, y2, test_size=0.2)\n",
    "lrmodel = LogisticRegression(solver='lbfgs')\n",
    "lrmodel.fit(x1train, y1train)\n",
    "ypredlr = lrmodel.predict(x1test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y1test, ypredlr))\n",
    "print(confusion_matrix(y1test, ypredlr))\n",
    "\n",
    "import numpy as np\n",
    "import numpy.matlib\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn import preprocessing\n",
    "import seaborn as sns\n",
    "import scipy.stats as st\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "X = np.array(x1train)\n",
    "Y = np.array(y1train)\n",
    "X1=np.array(x1test)\n",
    "Y1=np.array(y1test)\n",
    "x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "h = .02 # step size in the mesh\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h)\n",
    "Z = lrmodel.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.figure(1, figsize=(10, 10))\n",
    "plt.pcolormesh(xx, yy, Z, cmap=plt.cm.Paired)\n",
    "# Plot also the training/Testing points\n",
    "plt.scatter(X[:, 0], X[:, 1], c=Y, edgecolors='r', cmap=plt.cm.Paired)\n",
    "plt.scatter(X1[:, 0], X1[:, 1], c=Y1, edgecolors='b', cmap=plt.cm.Paired)\n",
    "plt.xlabel('Feature 0: Pregnancies')\n",
    "plt.ylabel('Feature 1:Glucose')\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.ylim(yy.min(), yy.max())\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
